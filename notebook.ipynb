{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNg0+0QMTW5MT8xH9vUt3NY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiphaineV/gpeg/blob/heavy/notebook-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k1QGkhbOb3g"
      },
      "source": [
        "## Loading Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAyJm-MIs0_8"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import scipy.sparse as sparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oe6rA--cBKZ",
        "outputId": "bedbbf9c-332e-4a74-910f-aae7d55290ba"
      },
      "source": [
        "!pip install memory-profiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting memory-profiler\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory-profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp36-none-any.whl size=30181 sha256=ac469df28e563b32e656f577ff0f8185b66f0c9f5dc1391d8fce814155a47629\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E27TZzXvcKPQ"
      },
      "source": [
        "%load_ext memory_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3tMuNeazqNVu"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jlf9P0WcqaP1"
      },
      "source": [
        "id = '1SujkUIqpPKg9LlJ8s77upbeTKkenmrLc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "itz-paJgzjac",
        "outputId": "924d6e92-8314-465e-8acb-2b6131381ff9"
      },
      "source": [
        "# -- some cleaning\n",
        "needed = True\n",
        "if needed :\n",
        "  %rm -R gpeg/\n",
        "  %rm context.py\n",
        "  %rm fastGraph.py\n",
        "  %rm node.py\n",
        "  %rm _recSystems.py\n",
        "  %rm trivialClf.py\n",
        "  %rm edge.py\n",
        "  %rm main.py \n",
        "  %rm scorer.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'gpeg/': No such file or directory\n",
            "rm: cannot remove 'context.py': No such file or directory\n",
            "rm: cannot remove 'fastGraph.py': No such file or directory\n",
            "rm: cannot remove 'node.py': No such file or directory\n",
            "rm: cannot remove '_recSystems.py': No such file or directory\n",
            "rm: cannot remove 'trivialClf.py': No such file or directory\n",
            "rm: cannot remove 'edge.py': No such file or directory\n",
            "rm: cannot remove 'main.py': No such file or directory\n",
            "rm: cannot remove 'scorer.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-7LxOj7GZ-n",
        "outputId": "edaa257d-4ff6-4774-ff85-384de2ff6083"
      },
      "source": [
        "!git clone -b heavy https://github.com/TiphaineV/gpeg.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpeg'...\n",
            "remote: Enumerating objects: 275, done.\u001b[K\n",
            "remote: Counting objects: 100% (275/275), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 441 (delta 185), reused 166 (delta 96), pack-reused 166\u001b[K\n",
            "Receiving objects: 100% (441/441), 1021.58 KiB | 7.86 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL9NNLW5sJ6X",
        "outputId": "10b0f665-3600-4cca-f3cd-b0a7da2e3167"
      },
      "source": [
        "cd gpeg/fast_implementation/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpeg/fast_implementation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gx_E85y5so7r"
      },
      "source": [
        "# Modules\n",
        "import numpy as np\n",
        "from _recSystems import _Clf\n",
        "from fastGraph import Graph\n",
        "from trivialClf import TrivialClf\n",
        "from scorer import ClfScorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RoGtfIGwqZFy"
      },
      "source": [
        "# -- Loading userData (heavy, takes around a minute)\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('userData.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S44J2u2T-Ha_"
      },
      "source": [
        "userDataStream = pd.read_csv('userData.csv', chunksize= 1e6) # please don't change chuksize"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jicOoSBDOguK"
      },
      "source": [
        "## Building Adjency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcEwOHi8wxOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca602b8e-e87e-4f97-f950-532b5f3baa01"
      },
      "source": [
        "%%time\n",
        "# -- Graph construction, nChunk * 1e6 rows are processed from movieLens 20M.\n",
        "# -- Takes around 2'30 for one chunk\n",
        "%memit graph = Graph(userDataStream, nChunk=20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph init ...\n",
            "Processing chunk 0.\n",
            "Processing chunk 1.\n",
            "Processing chunk 2.\n",
            "Processing chunk 3.\n",
            "Processing chunk 4.\n",
            "Processing chunk 5.\n",
            "Processing chunk 6.\n",
            "Processing chunk 7.\n",
            "Processing chunk 8.\n",
            "Processing chunk 9.\n",
            "Processing chunk 10.\n",
            "Processing chunk 11.\n",
            "Processing chunk 12.\n",
            "Processing chunk 13.\n",
            "Processing chunk 14.\n",
            "Processing chunk 15.\n",
            "Processing chunk 16.\n",
            "Processing chunk 17.\n",
            "Processing chunk 18.\n",
            "Processing chunk 19.\n",
            "peak memory: 4816.67 MiB, increment: 2432.86 MiB\n",
            "CPU times: user 48min 56s, sys: 9.94 s, total: 49min 6s\n",
            "Wall time: 49min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDUcVkyuor52"
      },
      "source": [
        "sparse.save_npz('adjency-20M1.npz', graph.adjency)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWP7KvD_OuPM"
      },
      "source": [
        "## Graph split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTIdketOwZ3V",
        "outputId": "3b16d414-e09b-4c54-c14f-d9e452f7e5a0"
      },
      "source": [
        "%%time\n",
        "# -- Parameters\n",
        "alpha = 0.1 # test proportion in the split\n",
        "\n",
        "# -- train_test_split\n",
        "%memit trainEdges, testEdges = graph.train_test_split(alpha= alpha)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 4334.77 MiB, increment: 1038.17 MiB\n",
            "CPU times: user 53.1 s, sys: 2.17 s, total: 55.2 s\n",
            "Wall time: 55.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By-Ea9BEOxCc"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8kucuXPMiY",
        "outputId": "eae44256-2340-4cf9-afa5-39ad13ccc3cc"
      },
      "source": [
        "# -- Loading userData\n",
        "%memit userData = pd.read_csv('userData.csv')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 6809.99 MiB, increment: 3085.10 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkSIgknaErjF",
        "outputId": "d558849f-bac6-4608-ddb4-13b68a6ca301"
      },
      "source": [
        "print(userData.head(10))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  userId  movieId  rating     timestamp_rating  tag timestamp_tag\n",
            "0           0       1        2     3.5  2005-04-02 23:53:47  NaN           NaN\n",
            "1           1       1       29     3.5  2005-04-02 23:31:16  NaN           NaN\n",
            "2           2       1       32     3.5  2005-04-02 23:33:39  NaN           NaN\n",
            "3           3       1       47     3.5  2005-04-02 23:32:07  NaN           NaN\n",
            "4           4       1       50     3.5  2005-04-02 23:29:40  NaN           NaN\n",
            "5           5       1      112     3.5  2004-09-10 03:09:00  NaN           NaN\n",
            "6           6       1      151     4.0  2004-09-10 03:08:54  NaN           NaN\n",
            "7           7       1      223     4.0  2005-04-02 23:46:13  NaN           NaN\n",
            "8           8       1      253     4.0  2005-04-02 23:35:40  NaN           NaN\n",
            "9           9       1      260     4.0  2005-04-02 23:33:46  NaN           NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyplwG2XEquN",
        "outputId": "5a986ae4-22ca-4123-fcec-8b7c4587deac"
      },
      "source": [
        "# -- Fitting recommender system\n",
        "clf = TrivialClf(userData, graph.adjency)\n",
        "%memit clf.fit(trainEdges)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 8511.39 MiB, increment: 1701.16 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82lOTWJWOa_j"
      },
      "source": [
        "## Scoring predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n12mho8gE-CL",
        "outputId": "d837bc6d-bee8-4c96-8010-8ff53155f6bb"
      },
      "source": [
        "# -- Prediction\n",
        "yPred = clf.predict(testEdges)\n",
        "yTrue = clf._get_labels(testEdges)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random prop 0.884362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKHG8yZi1z0G",
        "outputId": "167ef55f-b59f-4a9f-f525-0405d09dea9e"
      },
      "source": [
        "print(classification_report(yTrue, yPred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.68      0.79   1878724\n",
            "           1       0.06      0.32      0.10    121276\n",
            "\n",
            "    accuracy                           0.66   2000000\n",
            "   macro avg       0.50      0.50      0.44   2000000\n",
            "weighted avg       0.89      0.66      0.75   2000000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ40_3D4JE8P",
        "outputId": "7d5d00a6-d2a0-4129-db4e-f65ed56bb6f9"
      },
      "source": [
        "sample = np.random.choice(range(len(yPred)), size = 10)\n",
        "print(sample)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  75121  807253 1504984 1818109 1446333 1342727 1233002  488609 1412741\n",
            "  556195]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQUNBHw7O_ZE",
        "outputId": "465e5c52-dacf-4f26-be3b-e638aca43f07"
      },
      "source": [
        "print('Predictions \\n', yPred.iloc[sample].astype('uint8'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions \n",
            " 84581      1\n",
            "914097     0\n",
            "1701768    0\n",
            "424345     0\n",
            "1635326    1\n",
            "1518211    1\n",
            "1394552    0\n",
            "552907     1\n",
            "1597069    0\n",
            "629047     0\n",
            "dtype: uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BryjhxBPCj0",
        "outputId": "bf05ff99-4c40-4344-f420-f4c02f6a0685"
      },
      "source": [
        "print('Ground truth labels \\n', yTrue.iloc[sample])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ground truth labels \n",
            " 75121      0\n",
            "807253     0\n",
            "1504984    0\n",
            "1818109    0\n",
            "1446333    0\n",
            "1342727    0\n",
            "1233002    0\n",
            "488609     0\n",
            "1412741    0\n",
            "556195     0\n",
            "Name: rating, dtype: uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUHaN7f2PWk0",
        "outputId": "e4e42e1c-f06b-4f19-bfe6-10ea02bcd710"
      },
      "source": [
        "# -- Scoring\n",
        "scorer = ClfScorer()\n",
        "%memit score = scorer.score(clf, testEdges)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random prop 0.884362\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.94      0.68      0.79   1878724\n",
            "     class 1       0.06      0.32      0.10    121276\n",
            "\n",
            "    accuracy                           0.66   2000000\n",
            "   macro avg       0.50      0.50      0.44   2000000\n",
            "weighted avg       0.89      0.66      0.75   2000000\n",
            "\n",
            "peak memory: 8721.69 MiB, increment: 0.06 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}